#!/usr/bin/env python

# Copyright (c) YugaByte, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
# in compliance with the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software distributed under the License
# is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
# or implied.  See the License for the specific language governing permissions and limitations
# under the License.
#
"""Base script to run yugabyte processes locally.

Example use cases:

Creating a cluster with default settings
  yugabyte.py create

Creating a cluster with replication factor 5
  yugabyte.py --rf 5 create

Checking the status of your cluster
  yugabyte.py status

Adding a node to a running cluster
  yugabyte.py add_node

Stopping node #2 from your cluster
  yugabyte.py remove_node 2

Destroying your local cluster and its data
  yugabyte.py destroy
"""

import argparse
import errno
import glob
import logging
import signal
import subprocess
import sys
import time

import os
import shutil


DAEMON_TYPE_MASTER = 'master'
DAEMON_TYPE_TSERVER = 'tserver'
DAEMON_TYPES = [DAEMON_TYPE_MASTER, DAEMON_TYPE_TSERVER]


class ExitWithError(Exception):
    pass


def get_local_ip(index):
    return "127.0.0.{}".format(index)


class DaemonId:
    def __init__(self, daemon_type, index):
        if daemon_type not in DAEMON_TYPES:
            raise RuntimeError("Invalid daemon type: '{}'".format(daemon_type))

        self.daemon_type = daemon_type
        self.index = index

    def __str__(self):
        return "{}-{}".format(self.daemon_type, self.index)

    def is_master(self):
        return self.daemon_type == DAEMON_TYPE_MASTER

    def is_tserver(self):
        return self.daemon_type == DAEMON_TYPE_TSERVER

    def get_ip_address(self):
        return get_local_ip(self.index)


class ClusterOptions:

    def __init__(self):
        self.max_daemon_index = 20
        self.num_shards_per_tserver = None
        self.replication_factor = None

        self.cluster_base_dir = None

        self.custom_binary_dir = None
        self.script_dir = os.path.dirname(os.path.realpath(__file__))

        if os.environ.get('YB_USE_EXTERNAL_BUILD_ROOT') == '1':
            build_dir = os.path.dirname(self.script_dir) + '__build'
        else:
            build_dir = os.path.join(self.script_dir, "..", "build")

        self.build_bin_dir = os.path.realpath(
                os.path.join(build_dir, "latest", "bin"))

        self.drives = ["disk-{}".format(i) for i in xrange(1, 3)]

        self.placement_cloud = "cloud"
        self.placement_region = "region"
        self.placement_zone = "zone"

        self.require_clock_sync = False

        self.master_addresses = ""
        self.base_ports = {
                DAEMON_TYPE_MASTER: {
                    "http": 7000,
                    "rpc": 7100
                },
                DAEMON_TYPE_TSERVER: {
                    "http": 9000,
                    "rpc": 9100,
                    "redis_http": 11000,
                    "redis_rpc": 6379,
                    "cql_http": 12000,
                    "cql_rpc": 9042
                }
        }

        self.master_flags = []
        self.tserver_flags = []
        self.placement_info = []

    def parse_flag_args(self, flag_args):
        flags = [] if flag_args is None else flag_args.split(",")
        return [item.strip() for item in flags]

    def update_options_from_args(self, args):
        self.replication_factor = args.replication_factor
        self.custom_binary_dir = args.binary_dir
        self.cluster_base_dir = args.data_dir
        self.require_clock_sync = args.require_clock_sync
        self.num_shards_per_tserver = args.num_shards_per_tserver

        for arg in ["master_flags", "tserver_flags"]:
            try:
                parser_arg = getattr(args, arg)
            except AttributeError:
                parser_arg = None
            setattr(self, arg, self.parse_flag_args(parser_arg))

        try:
            placement_list = getattr(args, "placement_info").split(",")
        except AttributeError:
            placement_list = []

        for items in placement_list:
            t_item = tuple(items.split("."))
            if len(t_item) != 3:
                raise RuntimeError("Invalid argument: Each entry in placement info should "
                                   "specify cloud, region and zone as cloud.region.zone, "
                                   "seperated by commas")
            self.placement_info.append(t_item)

    def validate_daemon_type(self, daemon_type):
        if daemon_type not in DAEMON_TYPES:
            raise RuntimeError("Invalid daemon type: {}".format(daemon_type))
        # Validate the binary.
        self.get_server_binary_path(daemon_type)

    def validate_daemon_index(self, daemon_index):
        if daemon_index < 1 or daemon_index > self.max_daemon_index:
            raise RuntimeError("Invalid daemon node_id: {}".format(daemon_index))

    def get_server_binary_path(self, daemon_type):
        return self.get_binary_path("yb-{}".format(daemon_type))

    def get_binary_path(self, binary_name):
        # If the user specified a custom path, do not default back to anything else.
        if self.custom_binary_dir:
            binary_dirs = [self.custom_binary_dir]
            logging.info("Using custom binaries path: {}".format(self.custom_binary_dir))
        else:
            binary_dirs = [self.script_dir, self.build_bin_dir]

        for binary_dir in binary_dirs:
            path = os.path.join(binary_dir, binary_name)
            if not os.path.isfile(path) or not os.access(path, os.X_OK):
                logging.debug("No binary found at {}".format(path))
            else:
                return path
        raise RuntimeError("No binary found for {}. Considered binary directories: {}".format(
            binary_name, binary_dirs))

    def get_base_node_dirs(self, daemon_index):
        return ["{}/node-{}/{}".format(self.cluster_base_dir, daemon_index, drive)
                for drive in self.drives]

    def get_address(self, daemon_id, port_type, include_base_url=False):
        # We index nodes from 1, but we would like to always start from the actual base port for
        # all use cases, hence the -1.
        port_str = str(self.base_ports[daemon_id.daemon_type][port_type])
        base_local_url = daemon_id.get_ip_address()
        return port_str if not include_base_url else "{}:{}".format(base_local_url, port_str)


class ClusterControl:
    def __init__(self):
        self.options = ClusterOptions()
        self.args = None

        self.parser = argparse.ArgumentParser()
        self.subparsers = self.parser.add_subparsers()
        self.setup_parsing()

    def setup_base_parser(self, command, help=None):
        subparser = self.subparsers.add_parser(command, help=help)
        func = getattr(self, command, None)
        if not func:
            raise RuntimeError("Invalid command: {}".format(command))
        subparser.set_defaults(func=func)
        return subparser

    @staticmethod
    def add_extra_flags_arguments(subparser):
        subparser.add_argument(
            "--master_flags", default=None,
           help="Specify extra master flags as a set of key value pairs. "
                "Format (key=value,key=value)")

        subparser.add_argument(
            "--tserver_flags", default=None,
           help="Specify extra tserver flags as a set of key value pairs. "
                "Format (key=value,key=value)")

    def setup_parsing(self):
        self.parser.add_argument(
            "--binary_dir", default=None,
            help="Specify a custom directory in which to find the yugabyte binaries.")
        self.parser.add_argument(
            "--data_dir", default="/tmp/yugabyte-local-cluster",
            help="Specify a custom directory where to store data.")
        self.parser.add_argument(
            "--replication_factor", "--rf", default=3, type=int,
            help="Replication factor for the cluster as well as default number of masters. ")
        self.parser.add_argument(
            "--require_clock_sync", default=False, type=bool,
            help="Use ntpd for clock syncronization. Needed for real time dependent use-cases.")
        self.parser.add_argument(
            "--num_shards_per_tserver", default=2, type=int,
            help="Number of shards (tablets) to create per tablet server for each table.")

        subparsers = {}
        for cmd_name, help in (
                ("create", "Create a new cluster"),
                ("destroy", "Destroy the current cluster"),
                ("recreate", "Destroy the cluster and create it again"),
                ("restart", "Restart the current cluster all at once"),
                ("rolling_restart", "Restart the current cluster in a rolling fashion"),
                ("status", "Get info on the current cluster processes"),
                ("add_node", "Add a new tserver to the current cluster"),
                ("setup_redis", "Setup YugaByte to support Redis queries"),
                ("remove_node", "Remove a tserver from the current cluster")
            ):

            subparsers[cmd_name] = self.setup_base_parser(cmd_name, help=help)

        subparsers["create"].add_argument("--placement_info",
                    help="Specify the placement info in the following format: "
                    "cloud.region.zone,cloud.region.zone,cloud.region.zone")

        subparsers["add_node"].add_argument("--placement_info",
                    help="Specify the placement info in the following format:"
                    "cloud.region.zone")

        subparsers["remove_node"].add_argument("node_id", type=int,
               help="The id of the tserver to remove in range: 1-{}".format(
                  self.options.max_daemon_index))

        for cmd in ["create", "add_node"]:
            ClusterControl.add_extra_flags_arguments(subparsers[cmd])


    def run(self):
        self.args = self.parser.parse_args()
        self.options.update_options_from_args(self.args)
        self.args.func()

    def set_master_addresses(self, server_counts):
        self.options.master_addresses = ",".join(
            [self.options.get_address(DaemonId(DAEMON_TYPE_MASTER, i), "rpc", True)
             for i in range(1, server_counts + 1)])

    def get_number_of_servers(self, daemon_type):
        return len(glob.glob("{}/*/{}/yb-data/{}".format(
            self.options.cluster_base_dir, self.options.drives[0], daemon_type)))

    def get_pid(self, daemon_id):
        try:
            return int(subprocess.check_output(
                ["pgrep", "-f", "yb-{} .* --rpc_bind_addresses {}".format(
                    daemon_id.daemon_type,
                    daemon_id.get_ip_address())]))
        except subprocess.CalledProcessError as e:
            # From man pgrep
            #
            # EXIT STATUS
            # 0      One or more processes matched the criteria.
            # 1      No processes matched.
            # 2      Syntax error in the command line.
            # 3      Fatal error: out of memory etc.
            if e.returncode != 1:
                raise RuntimeError("Error during pgrep: {}".format(e.output))
            return 0

    def build_command(self, daemon_id, specific_arg_list):
        node_base_dirs = self.options.get_base_node_dirs(daemon_id.index)
        first_base_dir = node_base_dirs[0]

        command_list = [
            # Start with the actual binary
            self.options.get_server_binary_path(daemon_id.daemon_type),
            # Add in all the shared flags
            "--fs_data_dirs \"{}\"".format(",".join(node_base_dirs)),
            "--webserver_interface {}".format(daemon_id.get_ip_address()),
            "--rpc_bind_addresses {}".format(daemon_id.get_ip_address())
        ]
        binary_path = self.options.get_server_binary_path(daemon_id.daemon_type)
        www_path = os.path.realpath(os.path.join(os.path.dirname(binary_path), "..", "www"))
        version_metadata_path = os.path.realpath(
            os.path.join(os.path.dirname(binary_path), ".."))
        command_list.append("--version_file_json_path={}".format(version_metadata_path))
        if os.path.isdir(www_path):
            command_list.append("--webserver_doc_root \"{}\"".format(www_path))
        if bool(os.getenv("YB_DISABLE_CALLHOME")):
            command_list.append("--callhome_enabled=false")
        # Add custom args per type of server
        command_list.extend(specific_arg_list)
        # Redirect out and err and launch in the background
        command_list.append(">\"{0}/{1}.out\" 2>\"{0}/{1}.err\" &".format(
            first_base_dir, daemon_id.daemon_type))
        return " ".join(command_list)

    @staticmethod
    def customize_flags(flags, extra_flags):
        return flags + ["--{}".format(item) for item in extra_flags]

    def get_master_only_flags(self, daemon_id):
        command_list = [
            "--replication_factor={}".format(self.options.replication_factor),
            "--master_addresses {}".format(self.options.master_addresses)
        ]
        return self.customize_flags(command_list, self.options.master_flags)

    def get_tserver_only_flags(self, daemon_id):
        command_list = [
            "--tserver_master_addrs {}".format(self.options.master_addresses),
            "--memory_limit_hard_bytes {}".format(1024 * 1024 * 1024),
            "--yb_num_shards_per_tserver {}".format(self.options.num_shards_per_tserver),
            "--redis_proxy_bind_address {}".format(daemon_id.get_ip_address()),
            "--cql_proxy_bind_address {}".format(daemon_id.get_ip_address()),
            "--local_ip_for_outbound_sockets {}".format(daemon_id.get_ip_address())
        ]
        return self.customize_flags(command_list, self.options.tserver_flags)

    def get_placement_info_flags(self, placement_flags):
        return [
            "--placement_cloud {}".format(placement_flags[0]),
            "--placement_region {}".format(placement_flags[1]),
            "--placement_zone {}".format(placement_flags[2])
        ]

    def start_daemon(self, daemon_id):
        self.options.validate_daemon_type(daemon_id.daemon_type)
        self.options.validate_daemon_index(daemon_id.index)

        if not os.path.isdir(self.options.cluster_base_dir):
            raise ExitWithError("Found no cluster data at {}, cannot add node...".format(
                self.options.cluster_base_dir))

        for path in self.options.get_base_node_dirs(daemon_id.index):
            if not os.path.exists(path):
                os.makedirs(path)

        custom_flags = []
        if daemon_id.is_master():
            custom_flags = self.get_master_only_flags(daemon_id)
        else:
            custom_flags = self.get_tserver_only_flags(daemon_id)

        if len(self.options.placement_info) > 0:
            mod_val = daemon_id.index % len(self.options.placement_info)
            custom_flags.extend(self.get_placement_info_flags(self.options.placement_info[mod_val]))
        command = self.build_command(daemon_id, custom_flags)
        logging.info("Starting {} with:\n{}".format(daemon_id, command))
        os.system(command)

    def stop_daemon(self, daemon_id):
        pid = self.get_pid(daemon_id)
        if pid == 0:
            logging.info("Server {} already stopped".format(daemon_id))
            return
        logging.info("Stopping server {} PID={}".format(daemon_id, pid))
        # Kill the process.
        os.kill(pid, signal.SIGTERM)
        # Wait for process to stop.
        while True:
            try:
                logging.info("Waiting for server {} PID={} to stop...".format(daemon_id, pid))
                time.sleep(0.5)
                os.kill(pid, 0)
            except OSError as err:
                if err.errno == errno.ESRCH:
                    return

    def restart_daemon(self, daemon_id):
        self.stop_daemon(daemon_id)
        self.start_daemon(daemon_id)

    def create(self):
        server_counts = self.options.replication_factor
        self.set_master_addresses(server_counts)

        if len(self.options.placement_info) > server_counts:
            raise RuntimeError("Number of placement info fields is larger than "
                               "the replication factor and hence the number of servers.")

        if os.path.isdir(self.options.cluster_base_dir):
            raise ExitWithError(
                ("Found cluster data at {}, cannot create new cluster. Use --data_dir to "
                 "specify a different data directory if necessary, or 'destroy' / 'recreate'."
                 "commands to wipe out the old directory.").format(
                    self.options.cluster_base_dir))
        os.makedirs(self.options.cluster_base_dir)

        for daemon_type in DAEMON_TYPES:
            for daemon_index in range(1, server_counts + 1):
                daemon_id = DaemonId(daemon_type, daemon_index)
                pid = self.get_pid(daemon_id)
                if pid > 0:
                    logging.info("Server {} is running on PID={}".format(daemon_id, pid))
                else:
                    self.start_daemon(daemon_id)

    def set_running_master_addresses(self):
        self.set_master_addresses(self.get_number_of_servers(DAEMON_TYPE_MASTER))

    def add_node(self):
        self.set_running_master_addresses()
        daemon_type = DAEMON_TYPE_TSERVER
        num_servers = self.get_number_of_servers(daemon_type)
        if len(self.options.placement_info) > 1:
            raise RuntimeError("Please specify exactly one placement_info value.")
        self.start_daemon(DaemonId(daemon_type, num_servers + 1))

    def remove_node(self):
        # Note: remove_node in its current implementation would be more appropriately called
        # "stop_node". To properly decommission a local "node", we'll need to remove it from the
        # master's metadata and also delete the data directory.
        daemon_id = DaemonId(DAEMON_TYPE_TSERVER, self.args.node_id)
        logging.info("Stopping server {}".format(daemon_id))
        self.stop_daemon(daemon_id)

    def show_node_status(self, daemon_id):
        pid = self.get_pid(daemon_id)

        def get_address(port_type):
            return self.options.get_address(daemon_id, port_type, include_base_url=True)

        if pid == 0:
            logging.info("Server {} is not running".format(daemon_id))
        else:
            info_list = [
                ("type", daemon_id.daemon_type),
                ("node_id", daemon_id.index),
                ("PID", pid),
                ("admin service", "http://" + get_address("http"))
            ]
            if daemon_id.is_tserver():
                info_list.extend([
                    ("cql service", get_address("cql_rpc")),
                    ("redis service", get_address("redis_rpc"))
                ])
            logging.info("Server is running: {}".format(
                ", ".join(["{}={}".format(k, v) for k, v in info_list])))

    def status(self):
        self.for_all_daemons(self.show_node_status)

    def for_all_daemons(self, fn):
        """
        Run the given function for all daemons.
        """
        for daemon_type in DAEMON_TYPES:
            num_servers = self.get_number_of_servers(daemon_type)
            for daemon_index in range(1, num_servers + 1):
                fn(DaemonId(daemon_type, daemon_index))

    def destroy(self):
        self.for_all_daemons(self.stop_daemon)

        # Remove the top-level directory.
        top_level = self.options.cluster_base_dir
        if os.path.exists(top_level) and os.path.isdir(top_level):
            logging.info("Removing base directory: {}".format(top_level))
            shutil.rmtree(self.options.cluster_base_dir)

    def restart(self):
        self.set_running_master_addresses()
        self.for_all_daemons(self.stop_daemon)
        self.for_all_daemons(self.start_daemon)

    def rolling_restart(self):
        self.set_running_master_addresses()
        self.for_all_daemons(self.restart_daemon)

    def setup_redis(self):
        self.set_running_master_addresses()
        yb_admin_binary_path = self.options.get_binary_path("yb-admin")
        os.system("{} --master_addresses {} setup_redis_table".format(
            yb_admin_binary_path, self.options.master_addresses))

    def recreate(self):
        self.destroy()
        self.create()

if __name__ == "__main__":
    logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s %(levelname)s: %(message)s")

    try:
        ClusterControl().run()
    except ExitWithError, ex:
        logging.error(ex)
        sys.exit(1)
